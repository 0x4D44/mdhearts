# Hard AI (Stage 3) – High‑Level Design

Date: 2025‑10‑21
Owner: AI/Hearts bot
Scope: Improve “Hard” difficulty beyond the current shallow lookahead while keeping strict time budgets and preserving Normal heuristics’ stability.

## Background
Normal (heuristic) is tuned with moon logic, void‑aware follow‑ups, leader targeting, and endgame nuance. Hard adds a shallow, time‑capped lookahead:
- Current‑trick rollout with tiny continuation weights (feed leader, avoid self‑capture).
- Next‑trick probe when we win: branch top‑N next leads, now branching on first and second opponent replies (canonical + alt dump on void), under a strict cap.
- Early cutoff in choose() loop; explain path remains deterministic for tuning.

Observed behavior:
- Hard flips the top choice vs. Normal infrequently (~1–2% in sampled first‑decision snapshots), typically in leader‑feed/self‑capture edge cases.
- Latency is low with configured caps; scans ≤ top‑6 candidates; elapsed typically ~0–1ms on our dev setup.

Goal: Lift Hard’s tactical strength while staying within a small per‑decision envelope, and lock wins with goldens/benches.

## Objectives
1) Improve continuation accuracy when it matters (penalties on table, next‑lead control, QS/hearts dynamics).
2) Spend time adaptively: deepen where leverage is high; stay shallow elsewhere.
3) Keep deterministic and explainable outputs; preserve Normal behavior unless continuation clearly changes the outcome.
4) Maintain perf guardrails: typical < 20–30ms; avoid long‑tails.

## Success Metrics
- Primary: head‑to‑head advantage vs. Normal across random seeds.
  - Harness: add a CLI `--match-batch <games> [difficultyA difficultyB]` or a test helper to simulate N full rounds with the same RNG seed grid for both bots.
  - Report: average points per hand (lower is better), points to leader, QS captured counts, and stdev. Target: measurable reduction in points/hand (>0.2 pp over 5k–10k hands) with non‑overlapping 95% CI.
- Secondary: disagreement rate on first‑decision snapshots and curated scenarios; preserve/exceed existing goldens.
- Perf: typical decision latency under configured caps; no long‑tail spikes in benches.

## Review Findings & Revisions
- Determinism/test stability needs stronger guarantees when adding sampling and deeper branching.
  - Use a seeded, deterministic RNG keyed from snapshot seed + seat + trick fingerprint for any sampling; avoid OS RNG.
  - Keep strict, consistent tie‑breakers (by suit then rank) everywhere.
  - Provide a deterministic test mode that bypasses wall‑clock caps in favor of fixed operation budgets to avoid flaky tests.
- Time cap enforcement is currently scattered; nested probes can exceed the budget.
  - Introduce a central Deadline/Budget object passed through choose/rollout/probe to enforce a shared end time and cheap should_stop() checks.
  - Slice budget per candidate and per branch to avoid starving later candidates.
- Early cutoff can hide candidates whose continuation would change ranking.
  - Adopt a two‑phase loop: Phase A ranks by base only (with early cutoff); Phase B computes continuation for top‑K.
  - Expose K as an env knob with a conservative default.
- Monotonic fallback: if continuation probing is curtailed (cap reached), Hard should fall back to base ordering for any unprobed candidates to avoid arbitrary ranking changes vs. Normal.
- Sampling adds explain/choose parity concerns.
  - Ensure explain path uses the same deterministic sample set and ordering as choose (but without early cutoff), so tuning is meaningful.
- Testing with time caps can be flaky under load.
  - Add a test knob to disable wall‑clock and use step budgets; extend benches to report budget utilization.

## Proposed Changes

### 1. Search Deepening (Selective)
- Third‑opponent optional branching in next‑trick probe when time permits.
  - File: `crates/hearts-app/src/bot/search.rs` (`next_trick_probe`)
  - Strategy: maintain canonical path + one alternate (max‑penalty on void) for the third responder, gated by remaining time.
- Adaptive branch/time budget:
  - Broaden `branch_limit` and `next_branch_limit` when high‑leverage: penalties currently on trick, we are near 100, we lead with likely off‑suit voids, or leader‑target opportunity exists.
  - Narrow scanning when low‑leverage (clean follow suit, no penalties, early round).
  - Implementation: compute a lightweight “leverage score” inside `choose()` and `next_trick_probe()`; derive local limits from base env caps.
  - Leverage score (initial):
    - `L = w_pen*penalties_on_table + w_gap*min(30, leader_gap/10) + w_near100*I(self>=85) + w_lead*I(we_lead_next) + w_multi_void*I(multi_void_known)`
    - Start with `w_pen=3, w_gap=1, w_near100=2, w_lead=1, w_multi_void=1`; map L into {narrow, normal, wide} budget tiers.

### 2. Opponent Modeling (Lightweight)
- Probabilistic reply sampling (tiny N=2–4) for one opponent hop when voids exist:
  - Sample from a simple distribution consistent with known voids; prefer high‑penalty dumps and low‑rank follows.
  - Aggregate continuation as an average (or soft‑max) instead of single canonical/worst path.
  - Deterministic sampling: derive samples from a seeded PRNG (snapshot seed ⊕ seat ⊕ trick fingerprint); explain uses the same sample sequence.
  - Gate by the shared time budget; only for contested/penalty tricks.
- Strengthen void usage in follow‑ups used by Hard’s simulation:
  - When multiple opponents are void in lead suit, bias QS/hearts dump to the leader more aggressively (already partially present; expand cases).
  - File: `crates/hearts-app/src/bot/search.rs` (`choose_followup_search`).
  - Hearts‑broken respect: ensure sampling and follow‑ups never lead hearts illegally; rely on `RoundState` legality and add tests that assert no premature hearts leads in simulations.

### 3. Evaluation Upgrades (Tiny Continuation Weights)
- QS exposure risk: add a small penalty if our line increases the chance we take QS soon (e.g., playing high spades with many unseen spades; handing lead into spades while we hold K/A with Q unseen).
- Hearts control drift: bonus for keeping controlled lead with strong hearts when not near 100, penalty when handing lead into suits where we are weak and opponents are void.
- Planner‑level leader targeting nudge (Normal already includes a tiny version): mirror a small bias in Hard’s base sum before continuation to reinforce feeding leader when penalties > 0 and gap is meaningful.
  - Files: `crates/hearts-app/src/bot/search.rs` (`rollout_current_trick`, `next_trick_probe`), `crates/hearts-app/src/bot/play.rs` (`base_score` confirm weights).
- Moon‑mode alignment: when our style/tracker indicates Moon Considering/Committed, adjust continuation penalties/bonuses to not fight the moon attempt (e.g., reduce self‑capture penalty for hearts we intentionally take; increase continuation value for maintaining control and avoiding opponent hearts accumulation). Gate with tiny weights and lock with moon goldens.

### 4. Time and Branch Budgeting
- Two‑phase choose loop:
  - Phase A: rank by heuristic; scan with early cutoff and collect top‑K base totals quickly.
  - Phase B: spend remaining budget probing continuation for top‑1..2 candidates (or more if leverage score high), re‑ranking by base+cont.
- Keep explain path deterministic (no early cutoff), but print verbose base/cont/total when `MDH_DEBUG_LOGS=1`.
- Files: `crates/hearts-app/src/bot/search.rs` (choose/explain paths).
 - Centralize budget: pass a Deadline/Budget through all calls; expose cheap `should_stop()` checks within inner loops (including follow‑up selection) to honor caps.
 - Fairness: allocate a small per‑candidate slice for Phase B to avoid spending all remaining time on the first candidate.
 - Monotonicity guard: if Phase B is cut short, keep the Phase A (base) order for candidates that were not probed; do not interleave partially probed candidates in a way that degrades base order without strong evidence.

### 5. Configuration/Env Knobs
- Existing:
  - `MDH_HARD_BRANCH_LIMIT`, `MDH_HARD_NEXT_BRANCH_LIMIT`, `MDH_HARD_TIME_CAP_MS`, `MDH_HARD_EARLY_CUTOFF_MARGIN`.
  - `MDH_HARD_CONT_*`, `MDH_HARD_NEXT2_*` tiny continuation weights.
- Proposed (new):
  - `MDH_HARD_ADAPTIVE` (on/off): enable adaptive leverage‑based widening.
  - `MDH_HARD_QS_RISK_PER` (i32): penalty per expected QS risk point.
  - `MDH_HARD_CTRL_HEARTS_PER` (i32), `MDH_HARD_CTRL_HANDOFF_PEN` (i32): hearts control drift and bad‑handoff penalties.
  - `MDH_HARD_PHASEB_TOPK` (usize): how many top candidates get continuation probes in Phase B (default 2).
  - `MDH_HARD_DETERMINISTIC` (on/off): enable deterministic test mode; disables wall‑clock caps and uses fixed step budgets.
  - `MDH_HARD_TEST_STEPS` (usize): when deterministic mode is on, fixed overall step budget (e.g., 10_000 operations).
  - Defaults (initial):
    - `MDH_HARD_ADAPTIVE=0`, `MDH_HARD_PHASEB_TOPK=2`
    - `MDH_HARD_QS_RISK_PER=20`, `MDH_HARD_CTRL_HEARTS_PER=2`, `MDH_HARD_CTRL_HANDOFF_PEN=30`
    - `MDH_HARD_DETERMINISTIC=0` (tests enable it), `MDH_HARD_TEST_STEPS=10000`
  - All surfaced in `--show-weights` for transparency and printed in JSON explain.
- Knob discipline:
  - Group Hard continuation knobs under a single struct and print a canonical, sorted summary in `--show-weights` and `--explain-json` to ease diffing.
  - Provide a `--save-weights <path>` and `--load-weights <path>` (optional) to snapshot experimental configurations during tuning (future work).

## Testing and Quality Gates

### Goldens
- Add/expand tests under `crates/hearts-app/tests/`:
  - Disagreement cases (existing seeds): 1040(W), 1082(W), 1097(W), plus 1–2 South cases from compare‑batch.
  - Constructed flipping case: Hard’s continuation flips choice vs Normal for a penalty trick (capturing then feeding leader beats safe non‑capture).
  - Multi‑void follow‑ups: ensure simulated opponents dump appropriately without self‑feeding.
  - Near‑100 endgames: self‑protection and leader‑feed tradeoffs preserved.

### Benches/Perf
- Keep `benches/hard_decision.rs`; add assertions/logged targets:
  - Typical elapsed < 20–30ms caps; record scanned counts and elapsed distributions.
  - Track sensitivity to `branch_limit`, `next_branch_limit`, and time cap.
  - Report budget utilization (Phase A vs Phase B time and scans) to spot skew.
  - Include allocation counters where possible (e.g., via feature flag) to detect clone pressure; consider scratch arenas for RoundState copies if needed.

### Determinism/Explainability
- Ensure explain path remains deterministic and ordered; early cutoff only in choose path.
- `--explain-json` includes base/cont breakdown and Hard stats; console path prints verbose breakdown when `MDH_DEBUG_LOGS=1`.
- Ensure sampling uses the same deterministic sequence in explain and choose; include the leverage score and budgets chosen in verbose output.
 - Use a fixed, local PRNG (e.g., xorshift64) embedded in the code to avoid platform differences in RNG behavior; seed from snapshot seed ⊕ seat ⊕ trick fingerprint.
 - Debug logging overhead: ensure log gating uses OnceLock’d booleans checked in hot paths; avoid string formatting unless logging is on.

## Implementation Plan (Milestones)

M1: Adaptive Budget + Third‑Opponent Branch
- Add leverage scoring and adaptive widening.
- Extend next‑trick probe to optional third‑opponent branch under cap.
- Update `--show-weights` to include new knobs.
- Tests: smoke + disagreement goldens updated; basic perf check.

M1.5: Shared Deadline/Budget + Deterministic Mode
- Introduce a Deadline/Budget object; thread it through choose/rollout/probe/follow‑ups.
- Add `MDH_HARD_DETERMINISTIC` and `MDH_HARD_TEST_STEPS`; switch tests to deterministic mode.
- Expand Hard verbose to report leverage score, budgets, and Phase A/B scans.

M1.6: Monotonic Fallback + Logging Guards
- Enforce base‑order fallback for unprobed candidates; add tests that simulate cap hits and assert stable order.
- Audit logging gates in search/planners to ensure zero formatting when disabled; add a micro‑bench with logging on/off to quantify overhead.

M2: Continuation Feature Upgrades
- QS exposure risk and hearts control drift in continuation scoring.
- Small planner‑level nudge for leader targeting in Hard’s base combine step.
- Add constructed flipping golden; verify Normal goldens stable.

M3: Probabilistic Reply Sampling (Light)
- Introduce small‑N sampling for a single opponent hop when voids exist; average continuation.
- Tests for multi‑void/penalty dumps; ensure time cap respected and determinism preserved when `MDH_DEBUG_LOGS=0` (sampling seeded from snapshot seed).

M4 (Optional): Micro‑Optimizations and Guardrails
- Tiny transposition cache within a decision (keyed by trick state + provisional winner + leader target).
- Bench guard targets documented and optionally enforced in CI later.

## Risks and Mitigations
- Stability risk (unexpected flips):
  - Keep continuation weights tiny; add/expand goldens for critical patterns; gate deeper branching by leverage.
- Performance spikes:
  - Strict time caps; shared Deadline; early cutoff; adaptive narrowing on low‑leverage turns; optional caching; per‑candidate slices.
- Tuning complexity:
  - Use `--compare-batch` (with `--only-disagree`) to harvest cases; iterate with `--explain-json`; log changes in journal.
- Non‑determinism from wall clock/time slicing:
  - Use deterministic mode and seeded sampling in tests; keep explain path without early cutoff; enforce stable tie‑breakers.
- Double‑counting biases (Normal vs Hard continuation):
  - Keep continuation weights tiny and document layering; avoid replicating large leader‑feed effects that already exist in `base_score`; cap the combined effect.
- Moon‑mode interference:
  - Add moon‑aware continuation terms behind a gate; validate with moon goldens; ensure abort/commit transitions still behave as designed.

## Acceptance Criteria
- Disagreement rate increases modestly with measurable qualitative improvement (leader‑feed/self‑capture wins) across curated goldens.
- Typical decision time stays within target caps; no noticeable long tails in benches.
- Explain tooling shows coherent base/cont causality for flips; Normal goldens unaffected.
- CLI and README list any new knobs; popups remain opt‑in (`MDH_CLI_POPUPS=1`).
- Deterministic mode yields stable outputs across OS/toolchains; sampling consistency verified by goldens and JSON explains.
- Match harness shows a statistically significant improvement in average points/hand for Hard vs Normal over ≥5k hands, with 95% CI excluding zero.
- Goldens prefer structural assertions where possible (e.g., “penalties fed to leader and not self” for a scenario) to reduce brittleness to tiny weight nudges.

## Touchpoints (File Anchors)
- `crates/hearts-app/src/bot/search.rs`
  - `PlayPlannerHard::choose` (two‑phase scanning, adaptive budgets, early cutoff retained).
  - `rollout_current_trick`, `next_trick_probe` (QS risk, hearts control drift, third‑opponent branching, sampling).
  - `choose_followup_search` (multi‑void leader dump policy polish).
- `crates/hearts-app/src/bot/play.rs`
  - `base_score` (confirm/adjust tiny leader‑target nudge to complement continuation; keep small).
- `crates/hearts-app/src/cli.rs`
  - Console verbose for Hard (already gated by `MDH_DEBUG_LOGS=1`); ensure `--show-weights` prints new knobs.
- `README.md` / `docs/CLI_TOOLS.md`
  - Document new knobs and explain/compare usage.
- `crates/hearts-app/tests/`
  - New goldens: disagreements and constructed flip; near‑100 and multi‑void scenarios.
- `benches/hard_decision.rs`
  - Track elapsed/scanned; optional guard thresholds.

## Rollout & Measurement
1) Implement M1; run `--compare-batch <seat> 1000 200 --only-disagree` for all seats; capture CSVs under `designs/tuning/`.
2) Promote 3–5 disagreements to goldens; ensure stability across platforms.
3) Implement M1.5; enable deterministic mode in tests; update verbose to include budgets/leverage.
4) Implement M2; iterate weights using `MDH_HARD_*` overrides; lock with goldens.
5) Optionally implement M3; validate with additional tests; re‑bench.
6) Update journal and README after each milestone; keep popups disabled by default to avoid desktop interruption.
