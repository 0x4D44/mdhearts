Context
- Hard (FutureHard) now includes a tiny, deterministic endgame DP (choose-only) gated by `MDH_HARD_ENDGAME_DP_ENABLE`. It simulates ≤N remaining tricks and adds a small continuation signal (+feed-to-leader, −self-capture), clamped by `cont_cap`.
- Telemetry (endgame_dp_hits) and CLI/JSON surfaces are in place. Deterministic mixed-seat evaluations across seats/mixes show ≈0 aggregate delta under conservative caps (expected with tiny continuation).

Goal
- Achieve a measurable, stable Hard > Normal advantage (+1–2 pts/hand) without destabilizing existing behavior, and capture at least one deterministic flipping golden that exercises endgame DP.

Milestones
1) Robust flipping golden (≤3-card endgame)
   - Construct endgames where:
     - Path A wins the current trick (we lead next) and the next trick feeds the score leader with penalties.
     - Path B is a “safe now” alternative that does not lead next and yields no next‑trick benefit.
   - Target deterministic flip under current caps (no test-only suppression). Iterate hand layout and score gaps until stable on CI toolchains. Enable test when robust.
   - Artifacts: `crates/hearts-app/tests/hard_endgame_dp_flip_golden.rs` (enabled) and journal entry.

2) Endgame‑only tuning pass (guarded)
   - Increase only endgame continuation influence slightly (or apply a slightly higher endgame‑only continuation cap) with strict bounds. Keep explain deterministic.
   - Guardrails:
     - All existing goldens stable; perf unchanged (p95 within targets).
     - DP flipping golden remains stable.
   - Then run full-seat matrices (n≥1000/seat, two windows) and compute means + 95% CI. Promote defaults only if CI lower bound ≥ +0.3 and mean ≥ +1.0.

3) Evaluation and telemetry polish
   - Add optional CSV field (gated flag) for `endgame_dp_hits` in compare/match tools to aid tuning.
   - Consolidate a runbook to reproduce mixed-seat matrices with deterministic settings and capture summaries under `designs/tuning/`.

4) Documentation + Handoff
   - Summarize endgame DP design, knobs, and acceptance criteria in README/docs, linking to this note and the runbook.
   - Record before/after CSVs and CI summaries.

Acceptance Criteria
- Tests: flipping golden and all existing tests green on CI toolchains.
- Evaluation: aggregate advantage ≥ +1.0 with 95% CI lower bound ≥ +0.3 across at least two disjoint windows.
- Performance: no long‑tail regressions; deterministic budgets respected.

