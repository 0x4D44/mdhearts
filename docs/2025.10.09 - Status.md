# Status Report - October 9, 2025

**Last Updated**: 2025-10-09 ~23:00 (before system reboot)

---

## Executive Summary

**Gen2 Self-Play Training in Progress**: 75/200 iterations complete (37.5%)
- Training started: October 7, 2025 ~19:40
- Current runtime: ~27 hours
- ETA: ~46 more hours (completion October 10, ~20:45)
- Status: Running smoothly, strong convergence, no issues

**Goal**: Train Gen2 model via self-play to surpass Gen0's supervised learning ceiling

---

## Current Training Status

### Gen2 Training Progress

**Process**: Python training script running in background (bash shell e3e3ca)

**Command**:
```bash
cd python && python -m hearts_rl.train \
    --data ../selfplay_gen1.jsonl \
    --output ../gen2_weights.json \
    --iterations 200 \
    --checkpoint-dir ../gen2_checkpoints \
    --log-dir ../gen2_logs
```

**Training Metrics**:
| Iteration | Loss | Policy Loss | Value Loss | Notes |
|-----------|------|-------------|------------|-------|
| 1 | 0.2102 | 0.2297 | 0.0189 | Start |
| 20 | 0.0450 | 0.0464 | 0.0185 | |
| 40 | 0.0356 | 0.0363 | 0.0185 | |
| 50 | 0.0332 | 0.0338 | 0.0185 | Checkpoint saved |
| 60 | 0.0316 | 0.0320 | 0.0185 | |
| 70 | 0.0304 | 0.0307 | 0.0185 | |
| **75** | **0.0299** | **0.0302** | **0.0186** | **Current** |

**Loss Reduction**: 85.8% (0.2102 ‚Üí 0.0299)

**Rate**: ~22 min/iteration (has been consistent throughout)

**Remaining**: 125 iterations √ó 22 min = ~46 hours

**Expected Completion**: October 10, 2025 ~20:45

---

## Background Processes Running

There are multiple background bash shells monitoring/training:

1. **e3e3ca**: Gen2 training (PRIMARY - the one we care about)
2. **4c646f**: Auto-evaluation workflow (waiting for gen2_weights.json)
3. **c50086**: Gen2 training monitor
4. **161e97**: Old Gen0 training (probably stale)
5. **e0edfa**: Old Gen0 training (probably stale)
6. **c98e06**: Old Gen0 monitor (probably stale)

**After Reboot**: These processes will be terminated. Need to check training status.

---

## Files and Artifacts

### Input Data
- `selfplay_gen1.jsonl` (1.3M experiences, 25k games, 260 MB)
  - Generated from Gen0 playing against itself
  - Command used: `./mdhearts eval 25000 --self-play --weights final_weights.json --collect-rl selfplay_gen1.jsonl --reward-mode shaped`

### Gen0 Model (Original)
- `final_weights.json` (2.3 MB)
- Trained on 260k heuristic experiences (supervised learning)
- Performance: Between Easy and Normal difficulty
  - vs Easy: +48.3% improvement
  - vs Normal: -74.6% (loses)
  - vs Hard: -63.9% (loses)

### Gen2 Model (In Training)
- `gen2_weights.json` - **NOT YET CREATED** (will appear when training completes)
- Checkpoints: `gen2_checkpoints/checkpoint_50.pt` (saved at iteration 50)
- Logs: `gen2_logs/*.tfevents.*` (TensorBoard logs)

---

## After Reboot: Resume Checklist

### Step 1: Check Training Status

```bash
# Check if training completed
ls -lh gen2_weights.json

# Check if training process is still running
powershell "Get-Process python -ErrorAction SilentlyContinue"

# Check checkpoint directory
ls -lh gen2_checkpoints/
```

### Step 2: Resume Training if Interrupted

If `gen2_weights.json` does not exist and no training process is running:

```bash
# Resume from checkpoint (if available)
cd python && python -m hearts_rl.train \
    --data ../selfplay_gen1.jsonl \
    --output ../gen2_weights.json \
    --iterations 200 \
    --checkpoint-dir ../gen2_checkpoints \
    --log-dir ../gen2_logs \
    --resume ../gen2_checkpoints/checkpoint_50.pt
```

**Note**: The Python training script may or may not support `--resume`. If not:
1. Check which checkpoint exists (e.g., `checkpoint_50.pt`)
2. Restart training from scratch (not ideal but acceptable)
3. Or modify training script to support resume

### Step 3: Monitor Training Progress

```bash
# Watch training output (if running)
# Find the process and check its output

# Or monitor checkpoint files
ls -lht gen2_checkpoints/

# Or check TensorBoard logs
cd gen2_logs && ls -lh
```

---

## Next Steps (After Training Completes)

Once `gen2_weights.json` is created, the auto-evaluation workflow should run automatically. If not, run manually:

### Evaluation 1: Gen2 vs Normal Baseline
```bash
./target/release/mdhearts.exe eval 200 --ai normal --ai-test embedded --weights gen2_weights.json
```

### Evaluation 2: Gen2 vs Hard Baseline
```bash
./target/release/mdhearts.exe eval 200 --ai hard --ai-test embedded --weights gen2_weights.json
```

### Evaluation 3: Gen2 vs Gen0 (Self-Improvement Test)
```bash
./target/release/mdhearts.exe eval 200 \
    --ai-per-seat embedded,embedded,embedded,embedded \
    --weights-per-seat final_weights.json,final_weights.json,final_weights.json,gen2_weights.json
```

**Expected Results**:
- Gen2 should beat Normal (goal: overcome Gen0's supervised learning ceiling)
- Gen2 should beat Gen0 directly
- Gen2 may or may not beat Hard (stretch goal)

---

## Key Questions to Answer

1. **Did training complete?** Check for `gen2_weights.json`
2. **If interrupted, where did it stop?** Check latest checkpoint in `gen2_checkpoints/`
3. **Should we resume or restart?** Depends on checkpoint availability and iteration reached
4. **What iteration did we reach?** Check checkpoint file names or log files

---

## Technical Details

### Training Configuration
- **Algorithm**: PPO (Proximal Policy Optimization)
- **Batch size**: 256
- **Learning rate**: 0.0003
- **Clip epsilon**: 0.2
- **Gamma**: 0.99
- **GAE lambda**: 0.95
- **Epochs per iteration**: 4
- **Device**: CPU

### Mixed Evaluation System
- **Implementation**: Complete and production-ready
- **Files**:
  - `crates/hearts-app/src/eval/types.rs` (96 lines)
  - `crates/hearts-app/src/eval/mixed.rs` (401 lines)
  - `crates/hearts-app/src/eval/stats.rs` (254 lines)
  - `crates/hearts-app/src/cli.rs` (integrated)
- **Features**: Systematic rotation, policy-centric tracking, Mann-Whitney U test
- **Performance**: ~425 games/second

---

## Project Context

### What We've Accomplished
1. ‚úÖ Designed and implemented mixed AI evaluation system (HLD v3.0)
2. ‚úÖ Evaluated Gen0 model against all baselines (Easy/Normal/Hard)
3. ‚úÖ Identified supervised learning ceiling problem
4. ‚úÖ Generated 1.3M self-play experiences from Gen0
5. ‚úÖ Started Gen2 self-play training (37.5% complete)

### What's In Progress
- üîÑ Gen2 training (iteration 75/200)

### What's Next
- ‚è≥ Complete Gen2 training (~46 hours remaining)
- ‚è≥ Evaluate Gen2 vs baselines
- ‚è≥ Document Gen2 evaluation results
- ‚è≥ Determine if Gen2 surpassed supervised learning ceiling

---

## Important Notes

1. **Do NOT start new training** without checking existing checkpoints
2. **Checkpoints are valuable** - they represent 27+ hours of computation
3. **Auto-evaluation is configured** but may not survive reboot
4. **Loss is converging well** - 85.8% reduction with no signs of overfitting
5. **Training is CPU-bound** - runs on CPU, not GPU

---

## Quick Recovery Commands

```bash
# Check everything
ls -lh gen2_weights.json gen2_checkpoints/ selfplay_gen1.jsonl final_weights.json

# If training incomplete, check last checkpoint
ls -lht gen2_checkpoints/ | head

# If need to restart training (use last checkpoint if available)
cd python && python -m hearts_rl.train \
    --data ../selfplay_gen1.jsonl \
    --output ../gen2_weights.json \
    --iterations 200 \
    --checkpoint-dir ../gen2_checkpoints \
    --log-dir ../gen2_logs

# If training complete, run evaluations
./target/release/mdhearts.exe eval 200 --ai normal --ai-test embedded --weights gen2_weights.json
./target/release/mdhearts.exe eval 200 --ai hard --ai-test embedded --weights gen2_weights.json
./target/release/mdhearts.exe eval 200 \
    --ai-per-seat embedded,embedded,embedded,embedded \
    --weights-per-seat final_weights.json,final_weights.json,final_weights.json,gen2_weights.json
```

---

## References

- **Evaluation Results (Gen0)**: `docs/EVALUATION_RESULTS.md`
- **Implementation Progress**: `docs/IMPLEMENTATION_PROGRESS.md`
- **HLD v3.0**: `docs/HLD_MIXED_EVALUATION.md`
- **This Status Doc**: `docs/2025.10.09 - Status.md`

---

**End of Status Report**
