#!/usr/bin/env python3
"""
Generate dummy neural network weights for the embedded Hearts AI policy.

This script creates a simple MLP with random weights for testing purposes.
Architecture:
  - Input: 270 features (observation vector)
  - Hidden1: 256 units (ReLU)
  - Hidden2: 128 units (ReLU)
  - Output: 52 units (card logits)

The weights are serialized as Rust code for compile-time embedding.
"""

import argparse
import hashlib
import sys
from typing import List, Tuple
import random


def generate_layer_weights(input_size: int, output_size: int, seed: int) -> Tuple[List[float], List[float]]:
    """Generate weights and biases for a single layer using Xavier initialization."""
    random.seed(seed)

    # Xavier initialization: scale by sqrt(2 / (fan_in + fan_out))
    scale = (2.0 / (input_size + output_size)) ** 0.5

    # Weights: output_size Ã— input_size
    weights = [random.gauss(0, scale) for _ in range(output_size * input_size)]

    # Biases: output_size (initialized to small values)
    biases = [random.gauss(0, 0.01) for _ in range(output_size)]

    return weights, biases


def format_float_array(name: str, values: List[float], indent: int = 4) -> str:
    """Format a list of floats as a Rust array constant."""
    ind = " " * indent
    # Use 'static' instead of 'const' for large arrays to avoid clippy warning
    lines = [f"{ind}pub static {name}: [f32; {len(values)}] = ["]

    # Format 8 values per line for readability
    # Use 6 decimal places to avoid excessive precision warning
    for i in range(0, len(values), 8):
        chunk = values[i:i+8]
        formatted = ", ".join(f"{v:.6f}" for v in chunk)
        lines.append(f"{ind}    {formatted},")

    lines.append(f"{ind}];")
    return "\n".join(lines)


def compute_schema_hash() -> str:
    """Compute the same schema hash as build.rs."""
    schema_desc = (
        "v1.1.0:"
        "hand_onehot[52],"
        "seen_onehot[52],"
        "trick_led_suit[4],"
        "trick_cards[4][17],"
        "trick_count,"
        "my_trick_position,"
        "trick_pad,"
        "scores_relative[4],"
        "hearts_broken,"
        "tricks_completed,"
        "passing_phase,"
        "passing_direction[4],"
        "opp_voids[12],"
        "last_4_cards[68]"
    )
    return hashlib.sha256(schema_desc.encode()).hexdigest()


def generate_weights_file(seed: int, output_path: str):
    """Generate the complete weights file."""
    print(f"Generating dummy weights with seed {seed}...")

    # Network architecture
    input_size = 270
    hidden1_size = 256
    hidden2_size = 128
    output_size = 52

    # Generate weights for each layer
    w1, b1 = generate_layer_weights(input_size, hidden1_size, seed)
    w2, b2 = generate_layer_weights(hidden1_size, hidden2_size, seed + 1)
    w3, b3 = generate_layer_weights(hidden2_size, output_size, seed + 2)

    schema_hash = compute_schema_hash()
    schema_version = "1.1.0"

    # Generate Rust code
    content = f'''//! Generated neural network weights for embedded Hearts AI policy.
//!
//! This file is AUTO-GENERATED by tools/gen_dummy_weights.py
//! DO NOT EDIT MANUALLY
//!
//! Network architecture:
//!   - Input: {input_size} features
//!   - Hidden1: {hidden1_size} units (ReLU)
//!   - Hidden2: {hidden2_size} units (ReLU)
//!   - Output: {output_size} units (card logits)
//!
//! Generation seed: {seed}
//! Schema version: {schema_version}
//! Schema hash: {schema_hash}

/// Schema version this model was trained for
pub const MODEL_SCHEMA_VERSION: &str = "{schema_version}";

/// Schema hash this model expects
pub const MODEL_SCHEMA_HASH: &str = "{schema_hash}";

/// Layer 1: Input ({input_size}) -> Hidden1 ({hidden1_size})
pub mod layer1 {{
{format_float_array("WEIGHTS", w1)}

{format_float_array("BIASES", b1)}
}}

/// Layer 2: Hidden1 ({hidden1_size}) -> Hidden2 ({hidden2_size})
pub mod layer2 {{
{format_float_array("WEIGHTS", w2)}

{format_float_array("BIASES", b2)}
}}

/// Layer 3: Hidden2 ({hidden2_size}) -> Output ({output_size})
pub mod layer3 {{
{format_float_array("WEIGHTS", w3)}

{format_float_array("BIASES", b3)}
}}

#[cfg(test)]
mod tests {{
    use super::*;

    #[test]
    fn weight_dimensions_are_correct() {{
        assert_eq!(layer1::WEIGHTS.len(), {input_size} * {hidden1_size});
        assert_eq!(layer1::BIASES.len(), {hidden1_size});
        assert_eq!(layer2::WEIGHTS.len(), {hidden1_size} * {hidden2_size});
        assert_eq!(layer2::BIASES.len(), {hidden2_size});
        assert_eq!(layer3::WEIGHTS.len(), {hidden2_size} * {output_size});
        assert_eq!(layer3::BIASES.len(), {output_size});
    }}

    #[test]
    fn schema_matches_observation() {{
        // This will be validated at runtime by EmbeddedPolicy
        assert_eq!(MODEL_SCHEMA_VERSION, "1.1.0");
        assert!(!MODEL_SCHEMA_HASH.is_empty());
    }}
}}
'''

    with open(output_path, 'w') as f:
        f.write(content)

    total_params = len(w1) + len(b1) + len(w2) + len(b2) + len(w3) + len(b3)
    print(f"[OK] Generated {output_path}")
    print(f"  Total parameters: {total_params:,}")
    print(f"  Schema version: {schema_version}")
    print(f"  Schema hash: {schema_hash[:16]}...")


def main():
    parser = argparse.ArgumentParser(description="Generate dummy MLP weights for Hearts AI")
    parser.add_argument("--seed", type=int, default=42, help="Random seed for weight generation")
    parser.add_argument("--output", type=str,
                       default="crates/hearts-app/src/weights/generated.rs",
                       help="Output file path")

    args = parser.parse_args()

    try:
        generate_weights_file(args.seed, args.output)
        return 0
    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


if __name__ == "__main__":
    sys.exit(main())
