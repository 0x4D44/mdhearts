# Plan: Search vs Hard Evaluation Across Think Limits

_Last reviewed: 2025-11-05 19:45 CT_

## Objective
Quantify how the `SearchLookahead` bot performs against `FutureHard` under 5 s, 10 s, 15 s, and unlimited think-time caps. Generate reproducible CSV and Markdown artifacts plus telemetry showing the limits were respected.

## Current State
- CLI exposes `--think-limit-ms`, shorthand duration flags, and unlimited mode for every batch command.
- `tools/run_search_vs_hard.ps1` iterates seats and the four think caps, creating timestamped folders with match and compare CSVs plus per-limit summaries.
- Telemetry record structs include difficulty, phase, think-limit, elapsed, timeout, and fallback fields, but post-decision logging is not yet wired; only `PlayPlannerHard::choose_with_limit` emits a partial pre-decision entry.
- Controller autop path still bypasses the new `ThinkConfig` helpers, so Search runs do not yet receive enforced deadlines outside the Win32 worker.

## Stage 0 - Baseline & Assumptions
Status: Complete (2025-11-05 17:26)
- Verified current controller behaviour and documented deterministic seeds and env prerequisites.

## Stage 1 - CLI Think-Limit Integration
Status: Complete (2025-11-05 18:05)
- Added shared tail parser flags and env overrides so all CLI batch modes can set think limits without relying on the Win32 menu.

## Stage 2 - Batch Harness Automation
Status: Complete (2025-11-05 19:25)
- Extended `tools/run_eval.ps1` with a `-ThinkLimitMs` parameter and introduced `tools/run_search_vs_hard.ps1` to capture both match and compare batches for each cap.

## Stage 3 - Telemetry & Runtime Enforcement
Status: Complete (2025-11-05 22:05)
- Post-decision telemetry now records difficulty, cap, elapsed time, timeout state, and fallback labels from both controller and Win32 worker paths.
- `ThinkConfig` deadlines flow through `DecisionLimit` in `autoplay_one`; headless runs respect caps and surface fallback results.
- Added targeted regressions plus `tools/run_search_vs_hard.ps1 -VerifyTimeoutTelemetry` to force and validate timeout events across platforms.

## Stage 4 - Experiment Execution
Status: Ready
- Prereqs: deterministic env vars, release build, verified telemetry (see 2025-11-05_222055 smoke).
- Plan: run `tools/run_search_vs_hard.ps1 -CountWest 200 -CountSouth 200 -CountEast 200 -CountNorth 200 -VerifyTimeoutTelemetry` (plus `-Verbose` if needed) to generate the full dataset.
- Deliverables: per-cap CSVs, compare outputs, telemetry smokes, and consolidated summary under `designs/tuning/search_vs_hard/<timestamp>/`.

## Stage 5 - Analysis & Reporting
Status: Not started
- Build summary tables (mean penalty, std dev, win rate) and prepare Markdown narrative plus optional plots.

## Stage 6 - Wrap-up
Status: Not started
- Update README with the new flags, capture open questions, and package outputs for handoff/PR.

## Immediate Next Actions (to land the code changes)
1. Finish Stage 3 wiring (post-decision logging, controller deadlines, and Win32 parity).
2. Run smoke batches (e.g., 5 seeds per seat) with telemetry inspection to confirm limits enforce correctly.
3. Address any regressions in CLI or automation discovered during smokes.
4. Once Stage 3 passes, proceed with Stage 4 full runs followed by Stage 5 reporting.

## Risks and Follow-ups
- Unlimited mode could still overrun until `DecisionLimit` is fully enforced; watch for runaway think times.
- Telemetry sinks must remain backward compatible; confirm consumers can handle the new fields.
- Large batch runs may be slow; consider cutting seat counts if nightly windows are tight.



