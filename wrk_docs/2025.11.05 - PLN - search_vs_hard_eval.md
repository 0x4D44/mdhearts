# Plan: Search vs Hard Evaluation Across Think Limits

_Last reviewed: 2025-11-05 19:45 CT_

## Objective
Quantify how the `SearchLookahead` bot performs against `FutureHard` under 5 s, 10 s, 15 s, and unlimited think-time caps. Generate reproducible CSV and Markdown artifacts plus telemetry showing the limits were respected.

## Current State
- CLI exposes `--think-limit-ms`, shorthand duration flags, and unlimited mode for every batch command.
- `tools/run_search_vs_hard.ps1` iterates seats and the four think caps, creating timestamped folders with match and compare CSVs plus per-limit summaries.
- Telemetry records now include difficulty, think-limit, elapsed, timeout, and fallback values for every decision (pre/post).
- Both controller and Win32 autop paths enforce `ThinkConfig` deadlines and emit consistent telemetry, enabling headless verification via `--telemetry-out`.

## Stage 0 - Baseline & Assumptions
Status: Complete (2025-11-05 17:26)
- Verified current controller behaviour and documented deterministic seeds and env prerequisites.

## Stage 1 - CLI Think-Limit Integration
Status: Complete (2025-11-05 18:05)
- Added shared tail parser flags and env overrides so all CLI batch modes can set think limits without relying on the Win32 menu.

## Stage 2 - Batch Harness Automation
Status: Complete (2025-11-05 19:25)
- Extended `tools/run_eval.ps1` with a `-ThinkLimitMs` parameter and introduced `tools/run_search_vs_hard.ps1` to capture both match and compare batches for each cap.

## Stage 3 - Telemetry & Runtime Enforcement
Status: Complete (2025-11-05 22:05)
- Post-decision telemetry now records difficulty, cap, elapsed time, timeout state, and fallback labels from both controller and Win32 worker paths.
- `ThinkConfig` deadlines flow through `DecisionLimit` in `autoplay_one`; headless runs respect caps and surface fallback results.
- Added targeted regressions plus `tools/run_search_vs_hard.ps1 -VerifyTimeoutTelemetry` to force and validate timeout events across platforms.

## Stage 4 - Experiment Execution
Status: Complete (2025-11-06 09:06 CT)
- Ran `tools/run_search_vs_hard.ps1 -CountWest 200 -CountSouth 200 -CountEast 200 -CountNorth 200 -VerifyTimeoutTelemetry -Verbose`.
- Outputs: `designs/tuning/search_vs_hard/2025-11-06_090614/` with match/compare CSVs for all caps plus telemetry smokes (48 labeled timeouts each).
- Key deltas (avg Search - Hard per seat, consistent across caps): West +0.255, South +0.065, East +0.055, North -0.385.

## Stage 5 - Analysis & Reporting
Status: In progress (planning)
- Build summary tables (mean penalty, std dev, win rate) and prepare Markdown narrative plus optional plots.

## Stage 6 - Wrap-up
Status: Not started
- Update README with the new flags, capture open questions, and package outputs for handoff/PR.

## Immediate Next Actions
1. Compute Stage 5 summary metrics (per-cap averages, deltas, disagreement counts).
2. Review telemetry smokes for each cap and capture timeout/fallback stats in the analysis write-up.
3. Draft the Stage 5 report outline (tables + narrative) ahead of final polishing in Stage 6.

## Risks and Follow-ups
- Unlimited mode could still overrun until `DecisionLimit` is fully enforced; watch for runaway think times.
- Telemetry sinks must remain backward compatible; confirm consumers can handle the new fields.
- Large batch runs may be slow; consider cutting seat counts if nightly windows are tight.



