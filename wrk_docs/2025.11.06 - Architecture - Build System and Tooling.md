# Build System and Tooling Architecture

**Date:** 2025-11-06
**Scope:** Workspace, CI, scripts, assets, testing, packaging
**Purpose:** Development infrastructure and quality enforcement

## Executive Summary

The mdhearts project features a sophisticated build and tooling infrastructure supporting:
- **Cargo workspace** with 3 crates and strict quality gates
- **Dual-platform CI** (Linux + Windows) with evaluation smokes
- **14 shell scripts** for deterministic AI evaluation workflows
- **Comprehensive testing** with 74 test files and 2 benchmark suites
- **Windows installer** via Inno Setup
- **Asset management** for cards, icons, and resources

## Workspace Structure

### Cargo.toml (Root)
```toml
[workspace]
members = [
    "crates/hearts-core",
    "crates/hearts-ui",
    "crates/hearts-app"
]
resolver = "2"
```

**Resolver 2:** Modern dependency resolution with better feature unification

### Crate Dependency Graph

```
hearts-app (binary + platform)
├── hearts-core (game logic)
├── hearts-ui (presentation)
├── windows 0.62.1 (Win32/Direct2D)
├── serde + serde_json
├── once_cell
└── parking_lot

hearts-ui (presentation layer)
├── once_cell
├── serde + serde_json
└── (no dependencies on other workspace crates)

hearts-core (pure game logic)
├── rand 0.8
├── serde + serde_json
└── (no external workspace dependencies)
```

**Clean separation:** Core → UI → App, no circular dependencies

### .cargo/config.toml (Quality Enforcement)

```toml
[build]
rustflags = ["-D", "warnings"]
```

**Effect:** Treat all warnings as errors, enforces:
- No unused imports
- No dead code (must use #[allow(dead_code)] explicitly)
- No deprecated API usage
- All clippy warnings become errors


## Build Scripts

### hearts-app/build.rs

**Purposes:**
1. **Build timestamp generation:** Embeds build date for version info
2. **Windows resource compilation:** Links .RC file for icon and manifest

```rust
fn main() {
    // Generate build timestamp
    let timestamp = OffsetDateTime::now_utc()
        .format(&Rfc3339)
        .unwrap();
    println!("cargo:rustc-env=BUILD_TIMESTAMP={}", timestamp);
    
    // Compile Windows resources
    #[cfg(target_os = "windows")]
    embed_resource::compile("resources/mdhearts.rc", 
                             embed_resource::NONE);
}
```

**Dependencies:**
- `time 0.3` - Timestamp formatting
- `embed_resource 2` - Windows .RC compilation

**Outputs:**
- `BUILD_TIMESTAMP` env var available at compile time
- Embedded Windows icon and DPI manifest

### hearts-ui/build.rs

**Purpose:** Asset manifest generation (placeholder for future use)

Currently minimal, intended for:
- Validate assets exist
- Generate texture coordinate lookups
- Process card atlas JSON
- Create DPI variants

## CI Workflows

### .github/workflows/ci.yml

**Triggers:**
- Push to `main` or `master`
- Pull requests

**Jobs:**

#### 1. test (Matrix Build)
**Platforms:** `[ubuntu-latest, windows-latest]`

**Steps:**
1. Checkout code
2. Install Rust stable toolchain
3. Cache cargo registry and build artifacts
4. `cargo build --all --release`
5. `cargo test --all --verbose`

**Environment:**
```yaml
MDH_DEBUG_LOGS: "0"      # Disable verbose logging
MDH_CLI_POPUPS: "0"      # Disable Windows message boxes
```

**Cache key:** `${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}`

#### 2. eval-smoke (Linux only, PR only)
**Purpose:** Quick deterministic AI evaluation smoke test

**Configuration:**
```yaml
MDH_HARD_DETERMINISTIC: "1"
MDH_HARD_TEST_STEPS: "60"
MDH_FEATURE_HARD_STAGE12: "1"  # Enable all Hard features
```

**Seed ranges:** 5 seeds per seat (configurable via env)
- West: 1000-1004
- South: 1080-1084
- East: 2000-2004
- North: 1100-1104

**Script:** `tools/run_eval.sh`

#### 3. ultra-smoke (Linux, PR only)
**Purpose:** Ultra-fast mixed-seat validation (1 seed per seat)

**Configuration:**
```yaml
MDH_HARD_DETERMINISTIC: "1"
MDH_HARD_TEST_STEPS: "60"
SMOKE_COUNT: "2"           # 1-seed NNHH + 1-seed HHNN per seat
```

**Steps:**
1. Run `tools/smoke_fast.sh 100` (1 seed per seat, 2 configs)
2. Validate artifacts with `tools/check_smoke_artifacts.sh`
3. Upload CSV artifacts

**Artifacts:** `stage1-ultra-smoke-csv` (CSV files in `designs/tuning/stage1/smoke_release/`)

**Validation:** Checks that all expected CSV files exist and are non-empty

### .github/workflows/eval.yml

**Trigger:** Manual dispatch only

**Purpose:** Comprehensive evaluation runs (longer seed ranges)

**Configuration:** Similar to eval-smoke but with longer ranges and more outputs

**Use case:** Pre-release AI validation, tuning experiments

## Tooling Scripts

### Bash Scripts (12 total)

Located in `tools/` directory:

#### Evaluation Scripts

**1. run_eval.sh** (~100 lines)
- **Purpose:** Deterministic evaluation across all seats
- **Outputs:** 
  - `compare-batch` CSVs (Normal vs Hard disagreements)
  - `match-batch` CSVs (head-to-head penalties)
  - Summary markdown with aggregate stats
- **Configuration:** Env vars for seed ranges per seat

**2. smoke_fast.sh** (~50 lines)
- **Purpose:** Ultra-fast CI smoke (1-2 seeds per seat)
- **Hard flags:** Aggressive limits (60 steps, 150 branch limit, 5ms cap)
- **Configs:** NNHH and HHNN mixed-seat for each seat
- **Output:** `designs/tuning/stage1/smoke_release/*.csv`

**3. eval_all.sh** (~80 lines)
- **Purpose:** Comprehensive nightly evaluation
- **Seed ranges:** Wider ranges (200-500 seeds per seat)
- **Includes:** Compare, match, and mixed-seat evaluations

**4. nightly_eval.sh** (~60 lines)
- **Purpose:** Scheduled nightly runs (if configured)
- **Calls:** `eval_all.sh` with specific presets

**5. compare_small.sh** (~30 lines)
- **Purpose:** Quick compare test (10-20 seeds)
- **Output:** Console only (no file writes)

**6. compare_medium.sh** (~40 lines)
- **Purpose:** Medium compare test (50-100 seeds)
- **Output:** Timestamped CSV

#### Validation Scripts

**7. check_smoke_artifacts.sh** (~40 lines)
- **Purpose:** Validate smoke test CSV outputs
- **Checks:** Files exist, non-empty, valid CSV format
- **Exit code:** Non-zero if validation fails (CI gate)

**8. check_smoke_thresholds.sh** (~60 lines)
- **Purpose:** Validate smoke results against thresholds
- **Checks:** Hard penalty deltas within acceptable range
- **Thresholds:** Configurable per-seat expected values

#### Indexing Scripts

**9. index_compare.sh** (~30 lines)
- **Purpose:** Generate markdown index of compare CSV files
- **Output:** `designs/tuning/compare_index.md`
- **Format:** Table with seed ranges, seats, dates

**10. index_stage1_smokes.sh** (~35 lines)
- **Purpose:** Index Stage 1 smoke test results
- **Output:** `designs/tuning/stage1/smoke_index.md`

#### Commit Helpers

**11. commit_plan.sh** (~25 lines)
- **Purpose:** Structured commit workflow for tuning changes
- **Prompts:** Change description, affected files
- **Commit format:** Standardized tuning commit messages

**12. commit_plan_on_main.sh** (~20 lines)
- **Purpose:** Same as commit_plan but for main branch
- **Safety:** Confirms user is on main before committing

### PowerShell Scripts (2 total)

**1. run_eval.ps1** (~150 lines)
- **Purpose:** Windows equivalent of run_eval.sh
- **Parameters:** `-SeedStartWest`, `-CountWest`, etc.
- **Outputs:** Same CSV + markdown summary
- **Verbose flag:** `-Verbose` for detailed output

**2. run_search_vs_hard.ps1** (~100 lines)
- **Purpose:** Compare SearchLookahead vs Hard difficulty
- **Status:** Experimental (SearchLookahead not fully implemented)

### Script Architecture Patterns

**Common patterns across scripts:**

1. **Deterministic configuration:**
   ```bash
   export MDH_HARD_DETERMINISTIC=1
   export MDH_HARD_TEST_STEPS=120
   ```

2. **Feature flag enabling:**
   ```bash
   export MDH_FEATURE_HARD_STAGE12=1
   ```

3. **Output file naming:**
   ```bash
   timestamp=$(date +%Y-%m-%d_%H%M%S)
   output="designs/tuning/compare_${seat}_${timestamp}.csv"
   ```

4. **Progress indication:**
   ```bash
   echo "Running evaluation for ${seat} (${count} seeds)..."
   ```

5. **Error handling:**
   ```bash
   if [ $? -ne 0 ]; then
       echo "ERROR: Evaluation failed"
       exit 1
   fi
   ```


## Testing Infrastructure

### Test Organization

**Total test files:** 74 across all crates

**Location patterns:**
```
crates/hearts-core/src/
├── model/*.rs             # Inline unit tests
└── game/*.rs              # Inline unit tests

crates/hearts-app/src/
├── bot/tests/             # Bot behavior tests
├── tests/                 # Integration tests
└── benches/               # Criterion benchmarks
```

### Test Categories

#### 1. Core Game Logic Tests (hearts-core)
- **Card/Rank/Suit:** Basic type behavior
- **Hand:** Card management, sorting, contains checks
- **Trick:** Winner calculation, penalty counting
- **Round:** Legal move validation, hearts breaking, trick completion
- **Score:** Shoot the moon calculation, score updates
- **Serialization:** Snapshot export/import

**Example from round.rs:**
```rust
#[test]
fn legal_plays_must_follow_suit() {
    let round = /* setup */;
    let legal = round.legal_plays(seat);
    assert!(legal.iter().all(|c| c.suit == led_suit));
}
```

#### 2. Bot Behavior Tests (hearts-app)
- **Style determination:** When moon/hunt/cautious activates
- **Pass selection:** Priority-based card passing
- **Play scoring:** Feature weight application
- **Hard search:** Continuation scoring, tiering
- **Tracker:** Void inference, probability computation
- **Moon state:** Transition logic

**Example from bot/mod.rs:**
```rust
#[test]
fn style_moon_threshold() {
    let hand = /* strong moon hand */;
    let ctx = BotContext::new(/* ... */);
    assert_eq!(determine_style(&ctx), BotStyle::AggressiveMoon);
}
```

#### 3. Integration Tests
- **Snapshot round-trip:** Export then import snapshot
- **Deterministic replay:** Same seed → same game
- **Hard vs Normal:** Compare decisions across difficulties
- **Match simulation:** Full game simulation

### Benchmarking

**Criterion.rs suites:** 2 benchmarks

#### 1. heuristic_decision (Normal AI)
**File:** `crates/hearts-app/benches/heuristic_decision.rs`

**Measures:**
- `explain_candidates_for()` performance
- Across multiple seeds and seats
- Using stable snapshots

**Typical results:** 5-50 microseconds per decision

**Usage:**
```bash
cargo bench -p hearts-app --bench heuristic_decision
```

#### 2. hard_decision (Hard AI)
**File:** `crates/hearts-app/benches/hard_decision.rs`

**Measures:**
- `PlayPlannerHard::choose()` performance
- With deterministic step budget
- Various branch limits

**Configuration via env:**
```bash
MDH_HARD_BRANCH_LIMIT=6 cargo bench -p hearts-app --bench hard_decision
```

**Typical results:** 2-15ms per decision (120 steps)

**Target guidance:**
- Normal: Keep < 100 microseconds worst case
- Hard: Keep < 30ms typical case

### Test Execution

**Commands:**
```bash
# All tests
cargo test --all --verbose

# Specific crate
cargo test -p hearts-core
cargo test -p hearts-app

# Specific test
cargo test -p hearts-app test_name

# With output
cargo test -- --nocapture

# Benchmarks
cargo bench -p hearts-app
```

**CI execution:**
- Runs on every push and PR
- Both Linux and Windows
- Must pass for PR merge

## Asset Management

### Card Atlas

**Location:** `assets/cards.png`
**Format:** PNG, 1570 KB
**Dimensions:** 1248×384 pixels (13×3 card grid + backs row)

**Layout:**
- **Grid:** 13 ranks × 4 suits = 52 front faces
- **Card size:** 96×96 pixels each
- **Card backs:** 10 variants in bottom row
- **Metadata:** `assets/cards.json` describes layout

**cards.json structure:**
```json
{
  "layout": {
    "texture_width": 1248,
    "texture_height": 384,
    "card_width": 96,
    "card_height": 96,
    "back_start_x": 0,
    "back_start_y": 288
  },
  "back_variants": [
    "blue", "red", "castle", "weave", "crosshatch",
    "diamonds", "filigree", "modern", "classic", "abstract"
  ]
}
```

**Loading:** Compile-time embedding via `include_str!` in hearts-ui

### Windows Resources

**Location:** `crates/hearts-app/resources/`

**Files:**
- `mdhearts.rc` - Resource script (icon, manifest)
- `mdhearts.ico` - Application icon (multiple sizes)
- `mdhearts.exe.manifest` - DPI awareness and compatibility

**Manifest key settings:**
```xml
<dpiAware>True/PM</dpiAware>  <!-- Per-monitor DPI awareness -->
<dpiAwareness>PerMonitorV2</dpiAwareness>
```

**Compilation:** Handled by `embed-resource` in build.rs

### Adviser Bias (Optional)

**Location:** `assets/adviser/play.json`
**Purpose:** External AI bias tuning

**Format:**
```json
{
  "QC": -50,
  "AS": 100,
  "2H": 25
}
```

**Loading:** Runtime read when `MDH_HARD_ADVISER_PLAY=1`

## Packaging

### Inno Setup Installer

**Script:** `installers/Hearts.iss`

**Configuration:**
```
AppName=MDHearts
AppVersion=1.0.1
DefaultDirName={autopf}\MDHearts
DefaultGroupName=MDHearts
Compression=lzma2/ultra64
```

**Included files:**
- `mdhearts.exe` (from target/release/)
- `assets/cards.png`
- `assets/cards.json`
- Optional: adviser bias files

**Output:** `installers/MDHearts-1.0.1-Setup.exe`

**Build command:**
```bash
# 1. Build release binary
cargo build --release

# 2. Run Inno Setup compiler
iscc installers\Hearts.iss
```

**Installer features:**
- 64-bit only (x86_64-pc-windows-msvc)
- Desktop shortcut (optional)
- Start menu entry
- Uninstaller
- LZMA2 ultra compression


## Conclusion

The mdhearts build system and tooling infrastructure provides:

- Clean workspace structure with well-separated crates
- Strict quality enforcement via -D warnings and CI gates
- Comprehensive testing with 74 test files and benchmarks
- Dual-platform CI with Linux and Windows validation
- Rich evaluation tooling with 14 scripts for AI testing
- Deterministic evaluation for reproducible AI research
- Windows installer via Inno Setup
- Asset management for cards and resources
- Extensive documentation in docs/ and designs/

The build system demonstrates that Cargo workspaces + strict quality gates + rich tooling can support sophisticated game development with AI research workflows.
