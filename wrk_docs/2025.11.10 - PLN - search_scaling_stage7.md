# Plan: Search Scaling Stage 7 - Depth + Continuation

_Generated: 2025-11-10 10:25 CT_
_Related artifacts: wrk_docs/2025.11.07 - RPT - search_scaling_telemetry.md, wrk_docs/2025.11.09 - PLN - search_continuation_scaling.md, tmp/search_vs_mixed/2025-11-10_114256.json, tmp/search_vs_mixed/2025-11-10_114526.json_

## Objectives
- Convert higher think limits into measurable EV gains (>=0.25 penalty drop when moving 5s -> 15s for every Search seat in snnh + shsh mixes).
- Reduce heuristic brittleness by introducing selective two-ply search and data-fit continuation schedules.
- Automate telemetry-driven tuning so continuation weights, HardWeights, and analyzer checks self-correct as new data arrives.
- Preserve stability via deterministic tests, analyzer slope guards, and updated documentation.

## Success Criteria
1. Depth impact: selective two-ply path evaluated on >=30% of high-budget decisions; mixed-seat penalties improve by >=0.25 vs current baseline at 15s/20s limits.
2. Continuation responsiveness: continuation_scale_permil correlates with EV slope; analyzer slope check passes with >=0.15 penalty/seat gain when increasing limit buckets.
3. Heuristic learning: HardWeights loader ingests telemetry-derived tables and shows <0.1 penalty variance across seats when repeating 40-seed shsh runs.
4. Safety: controller::tests::search_autoplay_records_think_limit extended to assert continuation scaling + telemetry output; new selective-depth tests pass in CI.

## Stage Breakdown

### Stage 0 - Baseline consolidation & tooling (ETA: 0.5 day)
- Re-run tools/analyze_search_vs_mixed.py on 2025-11-10_114256 and 2025-11-10_114526 with slope calculations (temporary notebook or script) to capture penalty deltas per think limit.
- Snapshot configs (git diff, env overrides) and archive in wrk_docs/2025.11.07 - RPT - search_scaling_telemetry.md appendix.
- Open TODO: finalize analyzer patch that exposes penalty slope + continuation effectiveness metrics for downstream stages.

### Stage 1 - Selective two-ply search path (ETA: 1.5 days)
- Extend SearchConfig (crates/hearts-app/src/bot/search.rs) with knobs for max_depth, per-limit depth gating thresholds, and candidate quotas.
- Implement a limited two-ply evaluator: reuse PlayPlanner::explain_candidates for child nodes, but only for top-K cards that meet score/pressure gates; cache trick simulations to avoid recompute.
- Update Budget to track per-depth cost so the planner can bail early if depth expansion threatens the limit.
- Telemetry: add fields for depth2_samples, depth2_avg_branch, and depth2_pen_lift to Stats/NDJSON.
- Tests: create deterministic fixtures where deeper lookahead should flip the decision (for example, forced moon save) and wrap them in controller::tests.

### Stage 2 - Data-fit continuation scheduling (ETA: 1 day)
- Build a fitting script (Python notebook or Rust tool under tools/) that ingests telemetry JSON and outputs seat-aware logistic curves for phaseb_topk and ab_margin vs (limit ms, trailing gap, moon pressure).
- Replace the current ladder of "if ms >= ..." branches with the new schedule; keep env overrides for emergency tuning.
- Feed the fitted parameters through the runtime (possibly via JSON/TOML config) and ensure reload on startup.
- Update telemetry to log the selected schedule id + raw inputs so future analysis can validate usage.

### Stage 3 - Heuristic + HardWeights learning (ETA: 1 day)
- Author a telemetry-to-weights converter that aggregates continuation payoffs by seat/limit mix and writes tables under designs/tuning/search_vs_mixed/weights/.
- Modify HardWeights::weights() to optionally load these tables (fallback to current constants when absent) and surface which profile is active in debug logs.
- Enhance PlayPlanner::explain_candidates with protected-suit, partner-short, and safe-duck heuristics; gate behind a feature flag for quick regression toggles.
- Create focused unit/integration tests to ensure new heuristics respond to leader gap and moon pressure as intended.

### Stage 4 - Validation loop & automation (ETA: 1 day)
- Patch tools/analyze_search_vs_mixed.py to compute penalty slopes, continuation_scale_permil correlation, and selective-depth utilization; make the tool exit non-zero when goals regress.
- Add a helper script (PowerShell) that runs snnh + shsh sweeps, analyzer, and aggregates into a single report JSON for quick iteration.
- Execute 40-seed sweeps for snnh and shsh at 5/10/15/20s with new depth + heuristics enabled; archive artifacts under designs/tuning/search_vs_mixed/2025-11-xx_stage7/.
- Document outcomes in wrk_docs/2025.11.07 - RPT - search_scaling_telemetry.md and summarize EV shifts vs baseline.

### Stage 5 - Tests, docs, rollout (ETA: 0.5 day)
- Extend controller::tests::search_autoplay_records_think_limit to assert telemetry fields (depth2_samples, slope checks) and add a new test for analyzer regression guard (invoke script via CI harness).
- Update README and architecture docs with a "Search Scaling Stage 7" section describing the new knobs (MDH_SEARCH_DEPTH2_*, config file workflow, analyzer slope gates).
- Prep rollout checklist: feature flags, env overrides, telemetry monitoring, and rollback plan.
- Finalize journal + plan references (link this document, updated report, analyzer outputs) and notify stakeholders.

## Dependencies & Risks
- Long-running sweeps (40 seeds x 4 limits x 2 mixes) still take several hours; consider staggered schedules or cloud runners.
- Two-ply expansion increases complexity and may reintroduce timeouts; keep deterministic caps and telemetry watchdogs enabled during development.
- Data-fit schedules depend on telemetry quality; if logs are sparse or skewed, keep manual override switches documented.
- HardWeights auto-loading touches shared code paths with Hard bot; coordinate with maintainers to avoid regressions.

## Tracking
- Journal updates: continue logging in wrk_journals/2025.11.10 - JRN - search_scaling.md.
- Use update_plan entries (via CLI) after completing each stage to maintain visibility.
