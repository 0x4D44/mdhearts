# 2025-11-19 Code Review Report – MDHearts Workspace

## Methodology
- Followed the written plan (`wrk_docs/2025.11.19 - CR - plan.md`) by inventorying crates, inspecting rule/AI/platform modules, sampling assets/tools, and verifying docs/tests.
- Read representative files in each crate (`hearts-core/src/model/*.rs`, `hearts-app/src/{controller,bot,cli,telemetry}.rs`, `hearts-ui/src/*.rs`, platform Win32 host, docs).
- Exercised the workspace with `cargo llvm-cov --workspace --summary-only --test-threads=1` to uncover functional regressions during instrumentation.

## Repository Structure Overview
- **Crates:** `hearts-core` (rules + serialization), `hearts-app` (controller, bots, CLI, Win32 host), `hearts-ui` (asset manifest/theme helpers).
- **Tests:** >60 focused golden tests under `crates/hearts-app/tests/*.rs`, plus benches and integration data under `tests/`.
- **Tooling:** `.cargo/config` forces `-D warnings`; `tools/` folder provides evaluation scripts and automation; `.github` hosts CI workflows (not exhaustively reviewed).

## Findings by Area

### 1. hearts-core (rules engine)
- **Strengths:** Types are small, `#![deny(warnings)]` enforced, deterministic RNG seeding exists, unit coverage for Round/Passing/Score.
- **Risks:**
  1. **Validation duplication & panic risk (Medium):** `RoundState::validate_play` now performs all rule checks and is called from `play_card`, but several tests and helper routines still clone entire rounds to probe legality (e.g., numerous integration tests). This is more of a performance smell than correctness, yet it indicates callers rely on mutation for validation rather than safe query APIs. Consider exposing iterators over `legal_cards` that avoid allocations to reduce heavy cloning in integration tests/benches.
  2. **MatchState RNG reuse (Low):** `MatchState::with_seed_round_direction` consumes deck shuffles to “skip” rounds, reusing a single `StdRng`. While deterministic, there’s no protection against `round_number` overflow (>u32::MAX) or extremely long matches; consider saturating deck skips and documenting RNG behavior.

### 2. hearts-app – Controller & Telemetry
- **Global telemetry race (High):** Tests share a singleton sink. Running `cargo llvm-cov --workspace` causes `controller::tests::autoplay_timeout_records_fallback` to flake because other tests write telemetry between the “pre” and “post” assertions. Evidence: coverage run failed with `timed_out` = `None` and fallback = `None`. Recommendation: isolate telemetry per test (swap sink out, or let the test operate on a fresh sink) and consider making `controller::tests::autoplay_timeout_records_fallback` single-thread friendly by holding the mutex already used elsewhere.
- **Think-config mutation race (Medium):** `GameController::set_think_config` simply assigns the struct; any thread calling `autoplay_one` concurrently could observe inconsistent config. Controller currently isn’t `Send` but nothing prevents future use. Document non-thread-safe expectation or wrap config in `Arc<Mutex<_>>` before multi-threading arrives.
- **Global env toggles (Medium):** Tests and runtime features are toggled with unsafe environment-variable writes (e.g., `MDH_TEST_FORCE_AUTOP_TIMEOUT`, stage feature flags), risking test-order dependencies. Provide helper guards to restore env automatically.
- **Telemetry sink snapshot cost (Medium):** `TelemetrySink::snapshot` clones the entire `Vec<HardTelemetryRecord>` under write lock. Large sessions (GUI) will allocate and copy tens of thousands of records per export. Consider switching to bounded ring buffer + iterator streaming to avoid copying.

### 3. hearts-app – Bot system
- **Search golden drift (High):** `tests/hard_vs_normal_disagreement.rs` now fails (seed 1040) after game-rule changes. Since the test ensures Hard and Normal disagree only for curated cases, the failure indicates a golden needs refresh or that heuristics regressed. See coverage run logs: Normal top card changed from Ten? to King?. Requires either updating golden data or investigating heuristics.
- **Heavy reliance on global RNG/env (Medium):** `bot::tracker` and search modules sample from global RNG seeded by `rand::rngs::StdRng`. Many env vars (e.g., `MDH_HARD_BRANCH_LIMIT`) are read per call, which is convenient but costs repeated parsing and complicates reproducibility. Cache parsed config when `ThinkConfig` is created.
- **Unsafe usage limited (Low):** Most unsafe code is inside platform FFI; bot code is safe Rust.

### 4. Platform Layer (Win32)
- Not exhaustively reviewed due to size (~500kB). Spot checks show manual `unsafe` blocks for window proc, menu creation, etc., but no RAII wrappers. Recommend future audit for resource leaks (e.g., HMENU, bitmaps) and consistent error checking.

### 5. hearts-ui & assets
- Minimal crate; no issues found beyond placeholder manifest. Consider validating external manifest data (currently just logs errors).

### 6. Tests, Tools, Docs
- **Flaky tests (High):** Two failing tests observed under coverage run: `controller::tests::autoplay_timeout_records_fallback` (telemetry race) and `hard_vs_normal_disagreement` (outdated golden). Until addressed, CI jobs that enable instrumentation will fail.
- **Docs lagging (Medium):** `ARCHITECTURE.md` mentions “<15ms Hard AI decisions” and references preexisting Stage roadmaps but not the newly added reliability changes (addressed in this review via the doc update). Still, README and doc set don’t mention new helper APIs or telemetry retention fix.
- **Tooling:** `cargo llvm-cov` output shows target dir `target/llvm-cov-target`; ensure scripts clean it up to prevent drift. Several hundred CSV artifacts exist under `designs/tuning`, making repo heavy; consider moving to Git LFS or ignoring large generated data.

## Recommendations
1. **Stabilize telemetry + goldens before future coverage runs.** Provide helper to temporarily swap telemetry sink in tests, and reconcile `hard_vs_normal_disagreement` golden data with current heuristics.
2. **Document and enforce deterministic behavior.** Continue using `legal_cards` instead of ad-hoc cloning; consider property tests to ensure `legal_cards` + `play_card` parity.
3. **Audit global env usage.** Build helper guard for env vars to prevent leaking state across tests.
4. **Plan future coverage work.** Once tests are stable, rerun `cargo llvm-cov` to gather actual metrics (currently blocked by failing tests).
5. **Platform audit.** Schedule dedicated review of `platform/win32.rs` for `unsafe` correctness and resource lifetime tracking.

## Artifacts
- Review Plan: `wrk_docs/2025.11.19 - CR - plan.md`
- Coverage attempt log: `tmp_cov.txt`
- This Report: `wrk_docs/2025.11.19 - CR - full-review.md`
